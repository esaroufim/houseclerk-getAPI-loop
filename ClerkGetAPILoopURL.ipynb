{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7635b82-2d63-4644-9d02-15337dd32872",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###### FIRST CELL TO RUN ########\n",
    "#This script will run determine how many roll calls/sessions happened for a given year so that we know how which APIs we have \n",
    "#to call to retrieve all the data for a given year\n",
    "#######\n",
    "\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "## Enter URL here and the number of years you want the script to pull back from the site\n",
    "def fetch_votes_by_year_and_roll_and_save_to_csv(csv_filename):\n",
    "    base_url = \"https://clerk.house.gov/evs/{year}/roll{roll}.xml\"\n",
    "    years = [2021, 2022, 2023, 2024]\n",
    "\n",
    "## Create the csv and 3 headers\n",
    "    with open(csv_filename, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Year', 'Roll Number', 'URL'])  # Write the header row\n",
    "\n",
    "## Logic and shit\n",
    "        for year in years:\n",
    "            roll = 1\n",
    "            while True:\n",
    "                formatted_roll = str(roll).zfill(3)  # Ensure the roll number is formatted correctly (e.g., 001)\n",
    "                url = base_url.format(year=year, roll=formatted_roll)\n",
    "                \n",
    "                try:\n",
    "                    response = requests.get(url)\n",
    "                    # Check if the response status is 200 (OK) and assume no content indicates the end\n",
    "                    if response.status_code == 200 and response.content:\n",
    "                        writer.writerow([year, formatted_roll, url])  # Write the found data to the CSV\n",
    "                        roll += 1\n",
    "                    else:\n",
    "                        # If the status is not 200 or there's no content, break and move to the next year\n",
    "                        print(f\"No more rolls found for {year} at roll number {formatted_roll}. Moving to next year...\")\n",
    "                        break\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred: {e}\")\n",
    "                    break\n",
    "\n",
    "## Specify the CSV filename where the data will be saved\n",
    "## csv will have every www.url.com/XYZ.xml URL. This is basically a list of every individualized API that we need to call in the next step\n",
    "csv_filename = 'available_rolls.csv'\n",
    "\n",
    "# Fetch the available rolls and save them to the specified CSV\n",
    "fetch_votes_by_year_and_roll_and_save_to_csv(csv_filename)\n",
    "\n",
    "print(f\"Data saved to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e57a59c-f289-48a2-9e59-c826d66d7b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Second Cell to run once first cell is done#######\n",
    "### Make sure you only run this when ready. It will take a couple minutes to finish executing depending on your systems specs.\n",
    "\n",
    "import csv\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import requests\n",
    "\n",
    "# Function to read the CSV and extract unique URLs\n",
    "def read_csv(file_path):\n",
    "    urls = set()\n",
    "    with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            urls.add(row['URL'])\n",
    "    return urls\n",
    "\n",
    "# Worker function for making GET requests with logging\n",
    "def fetch_url(url):\n",
    "    print(f'Starting fetch for: {url}')\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        print(f'Completed fetch for: {url}')\n",
    "        return url, response.text\n",
    "    except requests.RequestException as e:\n",
    "        print(f'Error fetching {url}: {e}')\n",
    "        return url, str(e)\n",
    "\n",
    "# Main function to orchestrate the fetching and saving process with logging\n",
    "def main(csv_path):\n",
    "    urls = read_csv(csv_path)\n",
    "    responses = []\n",
    "\n",
    "    # This is where multi-threading happens, if we increase the size of the pull we can always increase the max_workers variable\n",
    "    # Use ThreadPoolExecutor to fetch data from URLs concurrently\n",
    "    with ThreadPoolExecutor(max_workers=20) as executor:\n",
    "        future_to_url = {executor.submit(fetch_url, url): url for url in urls}\n",
    "        for future in as_completed(future_to_url):\n",
    "            url = future_to_url[future]\n",
    "            try:\n",
    "                data = future.result()\n",
    "                responses.append(data)\n",
    "            except Exception as exc:\n",
    "                print(f'{url} generated an exception: {exc}')\n",
    "\n",
    "    # Save responses to a new CSV file with UTF-8 encoding\n",
    "    with open('Roll XML Data.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['URL', 'Response']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for url, response in responses:\n",
    "            writer.writerow({'URL': url, 'Response': response})\n",
    "\n",
    "# Uncomment the line below to run the script with the actual CSV path\n",
    "main('available_rolls.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b13318-7a0b-4987-ab0c-33d4313e2ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
